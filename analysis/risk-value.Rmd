---
title: "Risk Value Analysis"
author: "John Benninghoff"
date: '2024-11-03'
date-modified: '2024-11-22'
categories: risk quantification
order: 105
output:
  html_notebook:
    theme:
      version: 5
      preset: bootstrap
    css: assets/extra.css
    pandoc_args: --shift-heading-level-by=1
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: no
---

An exploration of the value of cybersecurity risk reduction.

# Questions/TODO

- [ ] Does `meanlog + log(0.5)` really reduce the log-normal mean by 50% as the simulation suggests?

```{r setup, message = FALSE, warning = FALSE}
library(poilog)
library(tibble)
library(dplyr)
library(quantrr)
library(formattable)
library(ggplot2)
library(plotly)
library(jbplot)
```

# Background

What is the value of a cybersecurity program? Put another way, how much should an organization pay
to reduce the likelihood of a breach or the expected impact? In this analysis, we compare two firms,
one with typical breach rate and impact, and a second that makes investments to reduce their risk.
Using Monte Carlo simulation, we can calculate the value of this risk reduction.

For the analysis, we use a 10 year horizon to fit with the typical executive tenure of 5-10 years.
(A 2023 [study](https://fortifyexperts.com/the-2023-fortune-500-cisos-analysis/) found that
CISOs at Fortune 500 companies had served an average of 8.3 years at the company and 4.5 years as
CISO)

# Baseline Risk

We can model baseline risk for a typical firm using
[quantrr](https://jabenninghoff.github.io/quantrr/) and data from the Cyentia 2022
[Information Risk Insights Study (IRIS)](https://www.cyentia.com/wp-content/uploads/IRIS-2022_Cyentia.pdf).

The 2022 IRIS found that the upper bound likelihood of a breach in the next year fit a Poisson
log-normal distribution with a mean ($\mu$) of -2.284585 and and standard deviation
($\sigma$) of 0.8690759.

As was done in the [breach rate analysis](breach-rates.Rmd), we can use trial and error to find a
reasonable value of $\lambda$ for a Poisson distribution that approximates these results:

```{r breach_table}
runs <- 1e6
lambda <- 0.138

breaches_poilog <- rpoilog(runs, mu = -2.284585, sig = 0.8690759, keep0 = TRUE)
breaches_pois <- rpois(runs, lambda = lambda)

breach_table <- function(breaches) {
  years <- length(breaches)
  tibble(
    "One or more" = sum(breaches >= 1) / years,
    "Two or more" = sum(breaches >= 2) / years,
    "Three or more" = sum(breaches >= 3) / years
  )
}

bind_rows(breach_table(breaches_poilog), breach_table(breaches_pois))
```

A Poisson distribution with a $\lambda$ of 0.138 approximates the Poisson log-normal model from the
Cyentia IRIS report.

```{r meanlog}
meanlog <- 12.55949
sdlog <- 3.068723
```

For the impact, we can use the log-normal loss model from IRIS, with a mean ($\mu$) of `r meanlog`
and standard deviation($\sigma$) of `r sdlog`.

Using the baseline parameters, we can simulate security events and losses over the next 10 years:

```{r baseline}
calc_risk("baseline", lambda, meanlog, sdlog, runs = 10)
```

# Net Present Value

We can calculate the (negative) net present value of the baseline security risk over the next ten
years by discounting future years. A discount rate of 5% is reasonable, and we use the formula
$\mathrm{NPV} = \large \frac{R_t}{(1+i)^t}$, treating year 1 as $t = 0$:

```{r baseline_value}
rate <- 0.05
baseline_value <- calc_risk("baseline", lambda, meanlog, sdlog, runs = 10) |>
  mutate(discount = (1 + rate)^(year - 1)) |>
  mutate(value = losses / discount)

baseline_value

baseline_value |>
  group_by(risk) |>
  summarize(npv = currency(sum(value)))
```

The baseline value is highly variable depending on how many breaches occur over the 10-year period.
We can forecast this range by running the 10-year simulation 100,000 times:

```{r baseline_forecast}
baseline_forecast <- calc_risk("baseline", lambda, meanlog, sdlog, runs = 100000 * 10) |>
  mutate(sim = ceiling(year / 10), .before = year) |>
  mutate(year = year %% 10) |>
  mutate(year = if_else(year == 0, 10, year)) |>
  mutate(discount = (1 + rate)^(year - 1)) |>
  mutate(value = losses / discount) |>
  group_by(sim) |>
  summarize(npv = sum(value))

baseline_forecast |>
  filter(npv != 0) |>
  ggplot(aes(npv)) +
  geom_hist_bw(bins = 100) +
  scale_x_log10(labels = scales::label_currency(scale_cut = scales::cut_short_scale())) +
  labs(x = NULL, y = NULL) +
  theme_quo()
```

That's a broad range, from \$100 or less to \$10B or more, with the most common non-zero value
around \$1M. But how many runs have no loss?

```{r no_loss}
baseline_forecast |>
  mutate(no_loss = (npv == 0)) |>
  count(no_loss)
```

About 25% of the time, there is no loss over the 10 year period.

# Security NPV

What is the NPV of a hypothetical security investment? The key ways we can reduce risk are by
lowering the likelihood, by lowering the impact, or both.

## Reduce Likelihood

Let's first look at an investment that reduces the breach rate by half:

```{r likelihood_forecast}
likelihood_forecast <- calc_risk("likelihood", lambda / 2, meanlog, sdlog, runs = 100000 * 10) |>
  mutate(sim = ceiling(year / 10), .before = year) |>
  mutate(year = year %% 10) |>
  mutate(year = if_else(year == 0, 10, year)) |>
  mutate(discount = (1 + rate)^(year - 1)) |>
  mutate(value = losses / discount) |>
  group_by(sim) |>
  summarize(npv = sum(value))
```

To measure the value of this investment, we calculate the difference between the baseline risk and
the risk after reducing the likelihood:

```{r likelihood_return}
likelihood_return <-
  full_join(baseline_forecast, likelihood_forecast, by = "sim", suffix = c("_base", "_reduced")) |>
  mutate(return = npv_base - npv_reduced)

likelihood_return |>
  summary()
```

The NPV of the risk reduction (return) is highly variable. Since we can't plot negative numbers
using a log scale, we can examine the data using the cumulative distribution function (CDF). We
limit the x-axis to zoom in to the 1% to 99% quantiles:

```{r likelihood_ecdf}
(likelihood_return |>
  ggplot(aes(return)) +
  stat_ecdf() +
  coord_cartesian(
    xlim = c(quantile(likelihood_return$return, 0.01), quantile(likelihood_return$return, 0.99))
  ) +
  labs(x = NULL, y = NULL) +
  theme_minimal()) |>
  ggplotly()
```

Reviewing the data:

- About 40% of the time, our security investment has a negative or zero return
- About 15% of the time, the security investment has a negative return of over $1M
- About 60% of the time, the security investment has a positive return
- About 32% of the time, the security investment has a positive return of over $1M

## Reduce Impact

Now let's look at an investment that reduces the breach impact by half:

```{r impact_forecast}
impact_forecast <- calc_risk("impact", lambda, meanlog + log(0.5), sdlog, runs = 100000 * 10) |>
  mutate(sim = ceiling(year / 10), .before = year) |>
  mutate(year = year %% 10) |>
  mutate(year = if_else(year == 0, 10, year)) |>
  mutate(discount = (1 + rate)^(year - 1)) |>
  mutate(value = losses / discount) |>
  group_by(sim) |>
  summarize(npv = sum(value))
```

To measure the value of this investment, we calculate the difference between the baseline risk and
the risk after reducing the likelihood:

```{r impact_return}
impact_return <-
  full_join(baseline_forecast, impact_forecast, by = "sim", suffix = c("_base", "_reduced")) |>
  mutate(return = npv_base - npv_reduced)

impact_return |>
  summary()
```

Again, the NPV of the risk reduction (return) is highly variable. We again examine the data using
the cumulative distribution function (CDF), limiting the x-axis:

```{r impact_ecdf}
(impact_return |>
  ggplot(aes(return)) +
  stat_ecdf() +
  coord_cartesian(
    xlim = c(quantile(impact_return$return, 0.01), quantile(impact_return$return, 0.99))
  ) +
  labs(x = NULL, y = NULL) +
  theme_minimal()) |>
  ggplotly()
```


Reviewing the data:

- About 50% of the time, our security investment has a negative or zero return
- About 22% of the time, the security investment has a negative return of over $1M
- About 50% of the time, the security investment has a positive return
- About 30% of the time, the security investment has a positive return of over $1M

# Analysis

What can we learn from these simulations? While a security investment is more likely than not to
have a positive return, it's not a particularly good bet. Over a reasonable planning horizon for a
typical executive, it's hard for an investment with a variable return to compete with investments
that have a clear expected positive return. As a CISO, it's a reasonable choice to simply maintain
the status quo of the baseline risk, as there's a good chance that there will be no breaches (25%)
or breaches with lower impact:

```{r quantile}
baseline_forecast |>
  pull(npv) |>
  quantile(0.5) |>
  currency()
```

Put another way, the analysis helps explain why firms don't invest more in security: the firms'
managers are better off prioritizing non-security investments, and (potentially) blaming the CISO
when breaches do occur, especially if they have limited their risk by purchasing cybersecurity
insurance. A rational manager will minimize investments in security unless mandated by insurance or
if increasing security spend is more than offset by reductions in premiums.

For the most part, this is what we often see in practice: security leaders struggling to get funding
to improve security beyond what is minimally expected by external stakeholders (clients, regulators,
and insurers). However, we also see certain larger organizations invest more in security, like large
banks and other financial institutions, why is this? Work done by VivoSecurity in
[forecasting data breaches](https://www.vivosecurity.com/download-isaca-philly-talk-may-2023)
suggests an answer. Vivo found a positive correlation between the size of an organization and the
likelihood of a security breach (which has also been identified by others, like
[Cyentia](https://www.cyentia.com/iris/)), and also found a negative correlation with the number of
CISAs and CISSPs on staff. The correlation was stronger when looking at the effect on larger
breaches.

I believe what this correlation shows is that the overall level of security investment at
a firm, as measured by the headcount of certified professionals, has a big impact on reducing the
likelihood of the largest breaches of \$1M or higher. From the same presentation, the Vivo model
predicts fairly frequent small breaches (under \$100K) at three of the largest Canadian banks, but
large breaches are very rare (under 1% for breaches in the \$1M-\$10M range). The high level of
investment at older banks may also be partly explained by the fact that their security programs
predate commercial cyber insurance. This insight is not captured in the simple model presented here.

# Implications

What are the implications for security? At a macro level, I think this is an argument for
regulation, either government regulation or private regulation through the insurance market.
Historically we've seen both happen in fire safety: government regulation through building codes has
reduced the risk of fire and loss of life over time, and insurance-driven regulations -
[UL](https://en.wikipedia.org/wiki/UL_(safety_organization)), founded as Underwriters Laboratories,
was initially funded by fire insurance companies.

At the firm level, I think this means that security leaders shouldn't present security as an
investment. As with safety, I think the main argument for better security is a moral or emotional
case: we care about security because we care about our customers, partners, and other stakeholders.
Also, people are typically loss-averse, so expressing security risk in those terms will better
connect with decision makers. Using
[Tail value at risk](https://en.wikipedia.org/wiki/Tail_value_at_risk) or
[Loss Exceedance Curves](https://www.cyentia.com/communicating-risk-loss-exceedance-curves/) express
loss in this way - "There's a 5% chance of losses exceeding $780,000 and a 1% of losses exceeding
$25,000,000 over the next year." I also think it means security leaders should be mindful of *how*
they spend their limited funds, by maximizing investments in
[what works](https://doi.org/10.1080/23738871.2024.2335461).
